{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing files: Empty_Grid\n",
      "Deleted existing file: E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/LG_SD_join\n",
      "Deleted existing file: E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/LG_SD_LD_join\n",
      "Deleted existing file: E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/LG_SD_LD_join\n",
      "Deleted existing file: E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/grid_LG_SD_LD\n",
      "Deleted existing file: E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/grid_LG_SD_LD_SA\n",
      "\n",
      "Creating grid...\n",
      "LG_index generated. \n",
      "\n",
      "Joining structure domains to grid_file...\n",
      "Structure domains joined.\n",
      "\n",
      "Joining lithology domains...\n",
      "Lithology domains joined.\n",
      "\n",
      "Created new file: E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/grid_LG_SD_LD\n",
      "\n",
      "Step 1 complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create PE_Grid step 1 of 3: Create indexes for local grids and SD, LD, SA domains \"\"\"\n",
    "\n",
    "### CODE TESETED AND SUCCESSFUL ###\n",
    "\n",
    "### INCLUDES A FUNCTION THAT CALCULATES DOMAIN INDEX IF NOT ALREADY IN THE DOMAIN SHAPEFILE ###\n",
    "\n",
    "### THIS CELL IS NEEDED IN THE FINAL SCRIPT ###\n",
    "\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import pandas as pd\n",
    "\n",
    "######################################################################################################################\n",
    "def ListFieldNames(featureclass):\n",
    "    \"\"\"\n",
    "    Lists the fields in a feature class, shapefile, or table in a specified dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    featureclass: <str>\n",
    "        Name of feature class\n",
    "    Can modify to include: wild_card, field_type in arcpy.ListFields()\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    <list>\n",
    "        Field names \n",
    "    \"\"\"\n",
    "    fc_wksp = arcpy.env.workspace + \"/\" + featureclass\n",
    "    \n",
    "    field_names = [f.name for f in arcpy.ListFields(featureclass)]\n",
    "    \n",
    "    return field_names\n",
    "\n",
    "\n",
    "def FieldValues(table, field):\n",
    "    \"\"\"\n",
    "    Create a list of unique values from a field in a feature class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table: <str>\n",
    "        Name of the table or feature class\n",
    "        \n",
    "    field: <str>\n",
    "        Name of the field \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    unique_values: <list>\n",
    "        Field values \n",
    "    \"\"\"\n",
    "    # Create a cursor object for reading the table\n",
    "    cursor = arcpy.da.SearchCursor(table, [field]) # A cursor iterates over rows in table\n",
    "\n",
    "    # Create an empty list for unique values\n",
    "    unique_values = []\n",
    "\n",
    "    # Iterate through rows\n",
    "    for row in cursor:\n",
    "        unique_values.append(row[0])\n",
    "    \n",
    "    return unique_values \n",
    "\n",
    "\n",
    "def IndexCalc(domainType, workspace_dir, domain_shp):\n",
    "    \"\"\"\n",
    "    Calculates index field for an STA domain type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    domainType: <str>\n",
    "        Name of the domain type.  Only the following two-letter strings should be used:\n",
    "        'LD' (lithologic domain)\n",
    "        'SD' (structural domain)\n",
    "        'SA' (secondary alteration)\n",
    "\n",
    "    workspace_dir: <str>\n",
    "        The working directory.  This should be the same as the location of the assessment geodatabase.  \n",
    "        \n",
    "    domain_shp: <str>\n",
    "        Full filepath and filename (including file extension) of the input shapefile or feature class.\n",
    "        Example 1: domain_shp = r\"P:\\02_DataWorking\\REE\\Central_App\\Structural_domains\\SD_CAB.shp\"\n",
    "        Example 2: domain_shp = workspace_dir + \"/\" + \"SD_CAB_2_copy.shp\"\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    domain_output_file: <file>\n",
    "        A copy of the input file with a new field for the domain index.  \n",
    "        *IMPORTANT*: This file will be saved to the same directory as domain_shp.\n",
    "    \"\"\"\n",
    "    domain_output_file = domain_shp[:-4] + \"_indexed.shp\"\n",
    "    try:\n",
    "        arcpy.CopyFeatures_management(domain_shp, domain_output_file)\n",
    "    except:\n",
    "        arcpy.Delete_management(domain_output_file)\n",
    "        arcpy.CopyFeatures_management(domain_shp, domain_output_file)\n",
    "\n",
    "    # Add to output file a new field for the index\n",
    "    arcpy.AddField_management(domain_output_file, domainType + '_index', \"TEXT\")\n",
    "\n",
    "    # Calculate index field, starting at index_0\n",
    "    counter = -1\n",
    "    with arcpy.da.UpdateCursor(domain_output_file, domainType + '_index') as cursor:\n",
    "        for row in cursor:\n",
    "            counter = counter + 1\n",
    "            row[0] = domainType + str(counter)\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "    return domain_output_file\n",
    "######################################################################################################################\n",
    "  \n",
    "    \n",
    "###### DEFINE THE WORKSPACE, INPUT, AND OUTPUT FILES HERE ######\n",
    "\n",
    "# # Identify working files, workspace, and input files (Powder River Basin)\n",
    "# workspace_dir = r\"E:/REE/PE_Score_Calc/Development/10-10-19\"\n",
    "# workspace_gdb = r\"REE_EnrichmentDatabase_PRB_cgc.gdb\"\n",
    "# workspace = workspace_dir + \"/\" + workspace_gdb\n",
    "\n",
    "# SD_input_file = r\"P:/02_DataWorking/REE/PRB/Domains/PRB_structure_domains_extended_GC.shp\"\n",
    "# LD_input_file = r\"P:/02_DataWorking/REE/PRB/Domains/PRB_lithology_domains_extended_GC.shp\"\n",
    "# # SA_input_file = r\"\"  # not developed for PRB\n",
    "\n",
    "\n",
    "# Identify working files, workspace, and input files (Central App coal source region)\n",
    "workspace_dir = r\"E:/REE/PE_Score_Calc/Development/10-10-19\"\n",
    "workspace_gdb = r\"REE_EnrichmentDatabase_CAB_cgc.gdb\"\n",
    "workspace = workspace_dir + \"/\" + workspace_gdb\n",
    "\n",
    "SD_input_file = r\"P:\\02_DataWorking\\REE\\Central_App\\Structural_domains\\SD_CAB_2.shp\"\n",
    "LD_input_file = r\"P:\\05_AnalysisProjects_Working\\REE\\App basin drainage\\AppBasinDrainageDomainPennsylvanian_BlakeBeuthin2008_snapped.shp\"\n",
    "# SA_input_file = r\"\"  # not yet developed for Central App\n",
    "\n",
    "\n",
    "# Set ArcGIS workspace environment\n",
    "arcpy.env.workspace = workspace\n",
    "\n",
    "# Final output files\n",
    "PE_Grid_calc = workspace + r\"/PE_Grid_calc\"\n",
    "PE_Grid_clean = workspace + r\"/PE_Grid_clean\"\n",
    "# PE_Grid_calc = workspace + r\"/PE_Grid_test_incl_UD\"\n",
    "\n",
    "# Grid local variables\n",
    "grid_file = \"Empty_Grid\"\n",
    "inFeatures = LD_input_file  # the grid extent will match the extent of this file (LD should have largest spatial extent)\n",
    "polygonWidth = \"1000 meters\"\n",
    "polygonHeight= \"1000 meters\"\n",
    "\n",
    "##################################################\n",
    "\n",
    "\n",
    "#------ THIS SECTION IS FOR RE-RUNNING THE CODE (RELEVANT DURING DEVELOPMENT) ------\n",
    "try:\n",
    "    arcpy.Delete_management(grid_file)\n",
    "    print(\"Deleted existing files:\", grid_file)\n",
    "except:\n",
    "    print(grid_file, \"not found in geodatabase!  Creating new...\")\n",
    "\n",
    "try:\n",
    "    LG_SD_out_featureclass = workspace + r\"/LG_SD_join\"\n",
    "    arcpy.Delete_management(LG_SD_out_featureclass)\n",
    "    print(\"Deleted existing file:\", LG_SD_out_featureclass)\n",
    "except:\n",
    "    print(LG_SD_out_featureclass, \"not found in geodatabase!  Will create new...\")\n",
    "\n",
    "try:\n",
    "    LG_SD_LD_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "    arcpy.Delete_management(LG_SD_LD_out_featureclass)\n",
    "    print(\"Deleted existing file:\", LG_SD_LD_out_featureclass)\n",
    "except:\n",
    "    print(LG_SD_LD_out_featureclass, \"not found in geodatabase!  Will create new...\")\n",
    "    \n",
    "try:\n",
    "    LG_SD_LD_SA_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "    arcpy.Delete_management(LG_SD_LD_SA_out_featureclass)\n",
    "    print(\"Deleted existing file:\", LG_SD_LD_SA_out_featureclass)\n",
    "except:\n",
    "    print(LG_SD_LD_SA_out_featureclass, \"not found in geodatabase!  Will create new...\")\n",
    "    \n",
    "try:\n",
    "    grid_LG_SD_LD = workspace + \"/grid_LG_SD_LD\"\n",
    "    arcpy.Delete_management(grid_LG_SD_LD)\n",
    "    print(\"Deleted existing file:\", grid_LG_SD_LD)\n",
    "except:\n",
    "    print(grid_LG_SD_LD, \"not found in geodatabase!  Will create new...\")\n",
    "    \n",
    "try:\n",
    "    grid_LG_SD_LD_SA = workspace + \"/grid_LG_SD_LD_SA\"\n",
    "    arcpy.Delete_management(grid_LG_SD_LD_SA)\n",
    "    print(\"Deleted existing file:\", grid_LG_SD_LD_SA)\n",
    "except:\n",
    "    print(grid_LG_SD_LD_SA, \"not found in geodatabase!  Will create new...\")\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"\\nCreating grid...\")\n",
    "\n",
    "# Create a grid of rectangular polygon features\n",
    "arcpy.GridIndexFeatures_cartography(grid_file,inFeatures, \"\", \"\", \"\", polygonWidth, polygonHeight) \n",
    "\n",
    "# Add field for LG_index\n",
    "arcpy.AddField_management(grid_file, \"LG_index\", \"TEXT\")\n",
    "\n",
    "# Calculate LG_index field, starting at LG1\n",
    "counter = -1\n",
    "with arcpy.da.UpdateCursor(grid_file, 'LG_index') as cursor:\n",
    "    for row in cursor:\n",
    "        counter = counter + 1\n",
    "        row[0] = 'LG' + str(counter)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"LG_index generated. \\n\")\n",
    "    \n",
    "# # Verify fields were added (used to QA/QC the script)\n",
    "# field_names = ListFieldNames(grid_file)\n",
    "# print(\"QAQC: LG index field name =\", field_names[-1], \"\\n\")\n",
    "\n",
    "# # Verify local grid correctly indexed (used to QA/QC the script)\n",
    "# LG_unique = FieldValues(grid_file, \"LG_index\")\n",
    "# print(\"QAQC: First row of LG_index =\", LG_unique[0], \"\\n\")\n",
    "\n",
    "\n",
    "##### STRUCTURE DOMAINS #####\n",
    "# Generate index field for domains if not already present\n",
    "domainType = 'SD'\n",
    "domain_shp = SD_input_file\n",
    "idx_test = ListFieldNames(SD_input_file)\n",
    "test = [i for i in idx_test if domainType in i]  # test if there is a field name containing domainType\n",
    "if test == []:  # if blank, calculate index field\n",
    "    print(\"Calculating SD index field...\")\n",
    "    SD_input_file = IndexCalc(domainType, workspace_dir, SD_input_file)\n",
    "    \n",
    "# Join local grid to structure domains\n",
    "print(\"Joining structure domains to grid_file...\")\n",
    "SD_target_features = grid_file\n",
    "SD_join_features = SD_input_file\n",
    "LG_SD_out_featureclass = workspace + r\"/LG_SD_join\"\n",
    "arcpy.SpatialJoin_analysis(SD_target_features, SD_join_features, LG_SD_out_featureclass, match_option=\"HAVE_THEIR_CENTER_IN\")\n",
    "print(\"Structure domains joined.\\n\")\n",
    "\n",
    "\n",
    "##### LITHOLOGIC DOMAINS #####\n",
    "# Generate index field for domains if not already present\n",
    "domainType = 'LD'\n",
    "domain_shp = LD_input_file\n",
    "idx_test = ListFieldNames(LD_input_file)\n",
    "test = [i for i in idx_test if domainType in i]  # test if there is a field name containing domainType\n",
    "if test == []:  # if blank, calculate index field\n",
    "    print(\"Calculating LD index field...\")\n",
    "    LD_input_file = IndexCalc(domainType, workspace_dir, LD_input_file)\n",
    "\n",
    "# Join lithologic domains\n",
    "print(\"Joining lithology domains...\")\n",
    "LD_target_features = LG_SD_out_featureclass\n",
    "LD_join_features = LD_input_file\n",
    "LG_SD_LD_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "arcpy.SpatialJoin_analysis(LD_target_features, LD_join_features, LG_SD_LD_out_featureclass, match_option=\"HAVE_THEIR_CENTER_IN\")\n",
    "print(\"Lithology domains joined.\\n\")\n",
    "\n",
    "\n",
    "# Copy SD and LD indices to new feature class\n",
    "grid_LG_SD_LD = workspace + \"/grid_LG_SD_LD\"\n",
    "arcpy.CopyFeatures_management(LG_SD_LD_out_featureclass, grid_LG_SD_LD)\n",
    "print(\"Created new file:\", grid_LG_SD_LD)\n",
    "\n",
    "\n",
    "### SA DOMAIN CODE BELOW STILL IN DEVELOPMENT; NEEDS TESTING ###\n",
    "\n",
    "# ##### SECONDARY ALTERATION DOMAINS #####\n",
    "# # Generate index field for domains if not already present\n",
    "# domainType = 'SA'\n",
    "# domain_shp = SA_input_file\n",
    "# idx_test = ListFieldNames(SA_input_file)\n",
    "# test = [i for i in idx_test if domainType in i]  # test if there is a field name containing domainType\n",
    "# if test == []:\n",
    "#     print(\"Calculating SA index field...\")\n",
    "#     SA_input_file = IndexCalc(domainType, workspace_dir, SA_input_file)\n",
    "\n",
    "# # Join secondary alteration domains\n",
    "# print(\"Joining secondary alteration domains...\")\n",
    "# SA_target_features = LG_SD_LD_out_featureclass\n",
    "# SA_join_features = SA_input_file\n",
    "# LG_SD_LD_SA_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "# arcpy.SpatialJoin_analysis(SA_target_features, SA_join_features, LG_SD_LD_SA_out_featureclass, match_option=\"HAVE_THEIR_CENTER_IN\")\n",
    "# print(\"Secondary alteration domains joined.\\n\")\n",
    "\n",
    "# # Copy SD, LD, and SA indices to new feature class  \n",
    "# grid_LG_SD_LD_SA = workspace + \"/grid_LG_SD_LD_SA\"\n",
    "# arcpy.CopyFeatures_management(LG_SD_LD_SA_out_featureclass, grid_LG_SD_LD_SA)\n",
    "# print(\"Created new file:\", grid_LG_SD_LD_SA)\n",
    "\n",
    "print(\"\\nStep 1 complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged DataFrames.\n",
      "Created E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/PE_Grid_calc\n",
      "\n",
      "Step 2 complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create PE_Grid step 2 of 3: Calculate unique domains (UD) using Pandas DataFrame \"\"\"\n",
    "\n",
    "### CODE TESTED AND SUCCESSFUL ###\n",
    "\n",
    "### THIS CODE IS NEEDED IN THE FINAL SCRIPT ONCE IT INCLUDES SA DOMAINS (SEE OTHER CELL) ###\n",
    "\n",
    "# THIS CELL DOES NOT INCLUDE SA DOMAIN TYPES \n",
    "\n",
    "# Create a list of local grid index values, then create DataFrame\n",
    "LG_index_values = FieldValues(grid_LG_SD_LD,'LG_index')\n",
    "df_grid_calc = pd.DataFrame(LG_index_values, columns = {'LG_index'})\n",
    "\n",
    "# Create a list of domain index values (e.g, LD1, LD2, LD3, LD4), then add to DataFrame\n",
    "LD_index_values = FieldValues(grid_LG_SD_LD, 'LD_index')\n",
    "df_grid_calc['LD_index'] = LD_index_values\n",
    "# df_grid_calc['LD_index'].value_counts()  # for development QAQC\n",
    "\n",
    "SD_index_values = FieldValues(grid_LG_SD_LD, 'SD_index') \n",
    "df_grid_calc['SD_index'] = SD_index_values\n",
    "# df_grid_calc['SD_index'].value_counts()  # for development QAQC\n",
    "\n",
    "# Create column for unique domain index 'UD_index'\n",
    "df_grid_calc['UD_index'] = 0\n",
    "\n",
    "# Group by unique LD and SD index value combinations\n",
    "grouped = df_grid_calc.groupby(['LD_index','SD_index'])\n",
    "\n",
    "# Create a Pandas Series that will contain the unique index combinations\n",
    "UD_lookup = grouped['UD_index'].unique()\n",
    "# print(UD_lookup['LD0']['SD0'])  # for development QAQC\n",
    "\n",
    "# Calculate the UD_index (this will be a Pandas Series that gets merged with the parent DataFrame)\n",
    "counter = 0\n",
    "for i in range(len(UD_lookup)):\n",
    "    UD_lookup[i] = \"UD\" + str(counter)\n",
    "    counter = counter + 1\n",
    "    # UD_lookup_df = pd.DataFrame(UD_lookup)  # this line is not needed; code works fine as Series (DataFrame not needed)\n",
    "\n",
    "# Merge calculated UD index with parent DataFrame\n",
    "df_grid_merged = df_grid_calc.merge(UD_lookup, how='left', left_on = ('LD_index', 'SD_index'), right_index=True, sort=False, indicator=True)\n",
    "\n",
    "# Tidy the column names and values\n",
    "df_grid_merged.rename(columns = {'UD_index_y': 'UD_index'}, inplace=True)\n",
    "df_grid_merged.drop(columns=['UD_index_x', '_merge'], inplace=True)\n",
    "df_grid_merged.fillna(value=0, inplace=True)\n",
    "    # df_grid_merged['_merge'].value_counts()  # for development only, to ensure proper merging\n",
    "\n",
    "print(\"Successfully merged DataFrames.\")\n",
    "\n",
    "\n",
    "\"\"\" Add UD_index to other indices in a feature class \"\"\"\n",
    "\n",
    "### CODE TESTED AND SUCCESSFUL ###\n",
    "\n",
    "# Export DataFrame as CSV\n",
    "exported_grid_df = workspace_dir + '/UD_domains_exported.csv'\n",
    "df_grid_merged.to_csv(exported_grid_df, index=False)\n",
    "\n",
    "# Convert the DataFrame CSV file to ArcGIS table (if not already created)\n",
    "try:\n",
    "    arcpy.TableToTable_conversion(exported_grid_df, workspace, \"exported_grid_df_table\")\n",
    "except:\n",
    "    print(\"DataFrame csv already converted to ArcGIS table!\")\n",
    "\n",
    "# Join DataFrame table to PE_Grid\n",
    "inFeatures = grid_LG_SD_LD\n",
    "joinField = \"LG_index\"\n",
    "joinTable = \"exported_grid_df_table\"\n",
    "fieldList = ['UD_index']\n",
    "arcpy.JoinField_management(inFeatures, joinField, joinTable, joinField, fieldList)\n",
    "\n",
    "# Create final copy of feature class with grid indicies\n",
    "try:\n",
    "    arcpy.CopyFeatures_management(grid_LG_SD_LD, PE_Grid_calc)\n",
    "except:\n",
    "    print(PE_Grid_calc, \"already exists, trying again...\")\n",
    "    arcpy.Delete_management(PE_Grid_calc)\n",
    "    arcpy.CopyFeatures_management(grid_LG_SD_LD, PE_Grid_calc)\n",
    "    \n",
    "print(\"\\nCreated\", PE_Grid_calc)\n",
    "\n",
    "print(\"\\nStep 2 complete\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\" Create PE_Grid step 2 of 3: Calculate unique domains (UD) using Pandas DataFrame \"\"\"\n",
    "\n",
    "### IN DEVELOPMENT ###\n",
    "\n",
    "### THIS CELL WILL BE NEEDED IN THE FINAL SCRIPT ###\n",
    "\n",
    "### ADDED SA DOMAIN TYPES; NEEDS TO BE TESTED AND VERIFIED ONCE SA DOMAINS ARE AVAILABLE ###\n",
    "\n",
    "# Create a list of local grid index values, then create DataFrame\n",
    "LG_index_values = FieldValues(grid_LG_SD_LD_SA,'LG_index')\n",
    "df_grid_calc = pd.DataFrame(LG_index_values, columns = {'LG_index'})\n",
    "\n",
    "# Create a list of domain index values (e.g, LD1, LD2, LD3, LD4), then add to DataFrame\n",
    "LD_index_values = FieldValues(grid_LG_SD_LD_SA, 'LD_index')\n",
    "df_grid_calc['LD_index'] = LD_index_values\n",
    "# df_grid_calc['LD_index'].value_counts()  # for development QAQC\n",
    "\n",
    "SD_index_values = FieldValues(grid_LG_SD_LD_SA, 'SD_index') \n",
    "df_grid_calc['SD_index'] = SD_index_values\n",
    "# df_grid_calc['SD_index'].value_counts()  # for development QAQC\n",
    "\n",
    "SA_index_values = FieldValues(grid_LG_SD_LD_SA, 'SD_index') \n",
    "df_grid_calc['SA_index'] = SA_index_values\n",
    "# df_grid_calc['SA_index'].value_counts()  # for development QAQC\n",
    "\n",
    "# Create column for unique domain index 'UD_index'\n",
    "df_grid_calc['UD_index'] = 0\n",
    "\n",
    "# Group by unique LD and SD index value combinations\n",
    "grouped = df_grid_calc.groupby(['LD_index','SD_index','SA_index'])\n",
    "\n",
    "# Create a Pandas Series that will contain the unique index combinations\n",
    "UD_lookup = grouped['UD_index'].unique()\n",
    "# print(UD_lookup['LD0']['SD0'])  # for development QAQC\n",
    "\n",
    "# Calculate the UD_index (this will be a Pandas Series that gets merged with the parent DataFrame)\n",
    "counter = 0\n",
    "for i in range(len(UD_lookup)):\n",
    "    UD_lookup[i] = \"UD\" + str(counter)\n",
    "    counter = counter + 1\n",
    "    # UD_lookup_df = pd.DataFrame(UD_lookup)  # this line is not needed; code works fine as Series (DataFrame not needed)\n",
    "\n",
    "# Merge calculated UD index with parent DataFrame\n",
    "df_grid_merged = df_grid_calc.merge(UD_lookup, how='left', left_on = ('LD_index', 'SD_index', 'SA_index'), right_index=True, sort=False, indicator=True)\n",
    "\n",
    "# Tidy the column names and values\n",
    "df_grid_merged.rename(columns = {'UD_index_y': 'UD_index'}, inplace=True)\n",
    "df_grid_merged.drop(columns=['UD_index_x', '_merge'], inplace=True)\n",
    "df_grid_merged.fillna(value=0, inplace=True)\n",
    "    # df_grid_merged['_merge'].value_counts()  # for development only, to ensure proper merging\n",
    "\n",
    "print(\"Successfully merged DataFrames.\")\n",
    "\n",
    "\n",
    "\"\"\" Add UD_index to other indices in a feature class \"\"\"\n",
    "\n",
    "### CODE TESTED AND SUCCESSFUL ###\n",
    "\n",
    "# Export DataFrame as CSV\n",
    "exported_grid_df = workspace_dir + '/UD_domains_exported.csv'\n",
    "df_grid_merged.to_csv(exported_grid_df, index=False)\n",
    "\n",
    "# Convert the DataFrame CSV file to ArcGIS table (if not already created)\n",
    "try:\n",
    "    arcpy.TableToTable_conversion(exported_grid_df, workspace, \"exported_grid_df_table\")\n",
    "except:\n",
    "    print(\"DataFrame csv already converted to ArcGIS table!\")\n",
    "\n",
    "# Join DataFrame table to PE_Grid\n",
    "inFeatures = grid_LG_SD_LD_SA\n",
    "joinField = \"LG_index\"\n",
    "joinTable = \"exported_grid_df_table\"\n",
    "fieldList = ['UD_index']\n",
    "arcpy.JoinField_management(inFeatures, joinField, joinTable, joinField, fieldList)\n",
    "\n",
    "# Create final copy of feature class with grid indicies\n",
    "try:\n",
    "    arcpy.CopyFeatures_management(grid_LG_SD_LD_SA, PE_Grid_calc)\n",
    "except:\n",
    "    print(PE_Grid_calc, \"already exists, trying again...\")\n",
    "    arcpy.Delete_management(PE_Grid_calc)\n",
    "    arcpy.CopyFeatures_management(grid_LG_SD_LD_SA, PE_Grid_calc)\n",
    "    \n",
    "print(\"Created\", PE_Grid_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to remove: SA_index from field_names_del\n",
      "\n",
      "Removing unnecessary fields from PE_Grid file...\n",
      "\n",
      "Created the indexed PE_Grid file to use for calculating PE Score:\n",
      " E:/REE/PE_Score_Calc/Development/10-10-19/REE_EnrichmentDatabase_CAB_cgc.gdb/PE_Grid_clean\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create PE_Grid step 3 of 3: Create a copy of PE_Grid that has only the fields for the indicies \"\"\"\n",
    "\n",
    "### CODE TESTED AND SUCCESSFUL ###\n",
    "\n",
    "### THIS CELL IS NEEDED IN THE FINAL SCRIPT ###\n",
    "\n",
    "# Create a clean copy of the grid with only essential and relevant fields for the grid indicies\n",
    "try: \n",
    "    arcpy.CopyFeatures_management(PE_Grid_calc, PE_Grid_clean)\n",
    "except:\n",
    "    arcpy.Delete_management(PE_Grid_clean)\n",
    "    arcpy.CopyFeatures_management(PE_Grid_calc, PE_Grid_clean)\n",
    "    \n",
    "# Update fields names\n",
    "field_names_del = ListFieldNames(\"PE_Grid_clean\")\n",
    "\n",
    "# List of fields to be preserved\n",
    "keep = [\"OBJECTID\", \"Shape\", \"Shape_Length\", \"Shape_Area\", \"LG_index\", \"SD_index\", \"LD_index\", \"SA_index\", \"UD_index\"]\n",
    "for i in keep:\n",
    "    try:\n",
    "        field_names_del.remove(i)\n",
    "    except:\n",
    "        print('failed to remove:', i, \"from field_names_del\")\n",
    "    \n",
    "# Delete unnecessary fields from PE_Grid_clean\n",
    "print(\"\\nRemoving unnecessary fields from PE_Grid file...\")\n",
    "for field in field_names_del:\n",
    "    arcpy.DeleteField_management(PE_Grid_clean, field)\n",
    "\n",
    "print(\"\\nCreated the indexed PE_Grid file to use for calculating PE Score:\\n\", PE_Grid_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OBJECTID',\n",
       " 'Shape',\n",
       " 'LG_index',\n",
       " 'SD_index',\n",
       " 'LD_index',\n",
       " 'UD_index',\n",
       " 'Shape_Length',\n",
       " 'Shape_Area']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListFieldNames(PE_Grid_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None, 'SD0', 'SD1', 'SD2', 'SD3', 'SD4', 'SD6'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(FieldValues(PE_Grid_clean, 'SD_index'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\"\"\" Create PE_Grid step 1 of 3: Create indexes for local grids and SD, LD, SA domains \"\"\"\n",
    "\n",
    "### CODE TESTED AND SUCCESSFUL ###\n",
    "\n",
    "### THIS CELL HAS BEEN COPIED AND SUCCESSFULLY UPGRADED; NOT NEEDED IN FINAL SCRIPT ###\n",
    "\n",
    "\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import pandas as pd\n",
    "\n",
    "######################################################################################################################\n",
    "def ListFieldNames(featureclass):\n",
    "    \"\"\"\n",
    "    Lists the fields in a feature class, shapefile, or table in a specified dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    featureclass: <str>\n",
    "        Name of feature class\n",
    "    Can modify to include: wild_card, field_type in arcpy.ListFields()\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    <list>\n",
    "        Field names \n",
    "    \"\"\"\n",
    "    fc_wksp = arcpy.env.workspace + \"/\" + featureclass\n",
    "    \n",
    "    field_names = [f.name for f in arcpy.ListFields(featureclass)]\n",
    "    \n",
    "    return field_names\n",
    "\n",
    "\n",
    "def FieldValues(table, field):\n",
    "    \"\"\"\n",
    "    Create a list of unique values from a field in a feature class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table: <str>\n",
    "        Name of the table or feature class\n",
    "        \n",
    "    field: <str>\n",
    "        Name of the field \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    unique_values: <list>\n",
    "        Field values \n",
    "    \"\"\"\n",
    "    # Create a cursor object for reading the table\n",
    "    cursor = arcpy.da.SearchCursor(table, [field]) # A cursor iterates over rows in table\n",
    "\n",
    "    # Create an empty list for unique values\n",
    "    unique_values = []\n",
    "\n",
    "    # Iterate through rows\n",
    "    for row in cursor:\n",
    "        unique_values.append(row[0])\n",
    "    \n",
    "    return unique_values \n",
    "\n",
    "######################################################################################################################\n",
    "  \n",
    "    \n",
    "###### DEFINE THE WORKSPACE, INPUT, AND OUTPUT FILES HERE ######\n",
    "\n",
    "# # Identify working files, workspace, and input files (Powder River Basin)\n",
    "# workspace_dir = r\"E:/REE/PE_Score_Calc/Development/10-10-19\"\n",
    "# workspace_gdb = r\"REE_EnrichmentDatabase_PRB_cgc.gdb\"\n",
    "# workspace = workspace_dir + \"/\" + workspace_gdb\n",
    "\n",
    "# SD_input_file = r\"P:/02_DataWorking/REE/PRB/Domains/PRB_structure_domains_extended_GC.shp\"\n",
    "# LD_input_file = r\"P:/02_DataWorking/REE/PRB/Domains/PRB_lithology_domains_extended_GC.shp\"\n",
    "# # SA_input_file = r\"\"  # not developed for PRB\n",
    "\n",
    "\n",
    "# Identify working files, workspace, and input files (Central App coal source region)\n",
    "workspace_dir = r\"E:/REE/PE_Score_Calc/Development/10-10-19\"\n",
    "workspace_gdb = r\"REE_EnrichmentDatabase_CAB_cgc.gdb\"\n",
    "workspace = workspace_dir + \"/\" + workspace_gdb\n",
    "\n",
    "SD_input_file = r\"P:\\02_DataWorking\\REE\\Central_App\\Structural_domains\\SD_CAB.shp\"\n",
    "LD_input_file = r\"P:\\05_AnalysisProjects_Working\\REE\\App basin drainage\\AppBasinDrainageDomainPennsylvanian_BlakeBeuthin2008_snapped.shp\"\n",
    "# SA_input_file = r\"\"  # not yet developed for Central App\n",
    "\n",
    "\n",
    "# Set ArcGIS workspace environment\n",
    "arcpy.env.workspace = workspace\n",
    "\n",
    "# Final output files\n",
    "PE_Grid_calc = workspace + r\"/PE_Grid_calc\"\n",
    "PE_Grid_clean = workspace + r\"/PE_Grid_clean\"\n",
    "# PE_Grid_calc = workspace + r\"/PE_Grid_test_incl_UD\"\n",
    "\n",
    "# Grid local variables\n",
    "grid_file = \"Empty_Grid\"\n",
    "inFeatures = LD_input_file  # the grid extent will match the extent of this file (LD should have largest spatial extent)\n",
    "polygonWidth = \"1000 meters\"\n",
    "polygonHeight= \"1000 meters\"\n",
    "\n",
    "##################################################\n",
    "\n",
    "\n",
    "#------ THIS SECTION IS FOR RE-RUNNING THE CODE (RELEVANT DURING DEVELOPMENT) ------\n",
    "try:\n",
    "    arcpy.Delete_management(grid_file)\n",
    "    print(\"Deleted existing files:\", grid_file)\n",
    "except:\n",
    "    print(grid_file, \"not found in geodatabase!  Creating new...\")\n",
    "\n",
    "try:\n",
    "    LG_SD_out_featureclass = workspace + r\"/LG_SD_join\"\n",
    "    arcpy.Delete_management(LG_SD_out_featureclass)\n",
    "    print(\"Deleted existing file:\", LG_SD_out_featureclass)\n",
    "except:\n",
    "    print(LG_SD_out_featureclass, \"not found in geodatabase!  Will create new...\")\n",
    "\n",
    "try:\n",
    "    LG_SD_LD_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "    arcpy.Delete_management(LG_SD_LD_out_featureclass)\n",
    "    print(\"Deleted existing file:\", LG_SD_LD_out_featureclass)\n",
    "except:\n",
    "    print(LG_SD_LD_out_featureclass, \"not found in geodatabase!  Will create new...\")\n",
    "    \n",
    "try:\n",
    "    LG_SD_LD_SA_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "    arcpy.Delete_management(LG_SD_LD_SA_out_featureclass)\n",
    "    print(\"Deleted existing file:\", LG_SD_LD_SA_out_featureclass)\n",
    "except:\n",
    "    print(LG_SD_LD_SA_out_featureclass, \"not found in geodatabase!  Will create new...\")\n",
    "    \n",
    "try:\n",
    "    grid_LG_SD_LD = workspace + \"/grid_LG_SD_LD\"\n",
    "    arcpy.Delete_management(grid_LG_SD_LD)\n",
    "    print(\"Deleted existing file:\", grid_LG_SD_LD)\n",
    "except:\n",
    "    print(grid_LG_SD_LD, \"not found in geodatabase!  Will create new...\")\n",
    "    \n",
    "try:\n",
    "    grid_LG_SD_LD_SA = workspace + \"/grid_LG_SD_LD_SA\"\n",
    "    arcpy.Delete_management(grid_LG_SD_LD_SA)\n",
    "    print(\"Deleted existing file:\", grid_LG_SD_LD_SA)\n",
    "except:\n",
    "    print(grid_LG_SD_LD_SA, \"not found in geodatabase!  Will create new...\")\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"/nCreating grid...\")\n",
    "\n",
    "# Create a grid of rectangular polygon features\n",
    "arcpy.GridIndexFeatures_cartography(grid_file,inFeatures, \"\", \"\", \"\", polygonWidth, polygonHeight) \n",
    "\n",
    "# Reassign the spatial index for the grid (ensures that 'OBJECTID' field starts at 1)\n",
    "# arcpy.AddSpatialIndex_management(grid_file)  \n",
    "\n",
    "# Add field for LG_index\n",
    "arcpy.AddField_management(grid_file, \"LG_index\", \"TEXT\")\n",
    "\n",
    "# Calculate LG_index field, starting at LG1\n",
    "counter = -1\n",
    "with arcpy.da.UpdateCursor(grid_file, 'LG_index') as cursor:\n",
    "    for row in cursor:\n",
    "        counter = counter + 1\n",
    "        row[0] = 'LG' + str(counter)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"LG_index generated. \\n\")\n",
    "    \n",
    "# Verify fields were added (used to QA/QC the script)\n",
    "field_names = ListFieldNames(grid_file)\n",
    "print(\"QAQC: LG index field name =\", field_names[-1], \"\\n\")\n",
    "\n",
    "# Verify local grid correctly indexed (used to QA/QC the script)\n",
    "LG_unique = FieldValues(grid_file, \"LG_index\")\n",
    "print(\"QAQC: First row of LG_index =\", LG_unique[0], \"\\n\")\n",
    "\n",
    "# Join local grid to structure domains\n",
    "print(\"Joining structure domains to grid_file...\")\n",
    "SD_target_features = grid_file\n",
    "SD_join_features = SD_input_file\n",
    "LG_SD_out_featureclass = workspace + r\"/LG_SD_join\"\n",
    "arcpy.SpatialJoin_analysis(SD_target_features, SD_join_features, LG_SD_out_featureclass, match_option=\"HAVE_THEIR_CENTER_IN\")\n",
    "print(\"Structure domains joined.\\n\")\n",
    "\n",
    "# Join lithologic domains\n",
    "print(\"Joining lithology domains...\")\n",
    "LD_target_features = LG_SD_out_featureclass\n",
    "LD_join_features = LD_input_file\n",
    "LG_SD_LD_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "arcpy.SpatialJoin_analysis(LD_target_features, LD_join_features, LG_SD_LD_out_featureclass, match_option=\"HAVE_THEIR_CENTER_IN\")\n",
    "print(\"Lithology domains joined.\\n\")\n",
    "\n",
    "# Copy SD and LD indices to new feature class\n",
    "grid_LG_SD_LD = workspace + \"/grid_LG_SD_LD\"\n",
    "arcpy.CopyFeatures_management(LG_SD_LD_out_featureclass, grid_LG_SD_LD)\n",
    "print(\"Created new file:\", grid_LG_SD_LD)\n",
    "\n",
    "\n",
    "### SA DOMAIN CODE BELOW STILL IN DEVELOPMENT; NEEDS TESTING ###\n",
    "# # Join secondary alteration domains\n",
    "# print(\"Joining secondary alteration domains...\")\n",
    "# SA_target_features = LG_SD_LD_out_featureclass\n",
    "# SA_join_features = SA_input_file\n",
    "# LG_SD_LD_SA_out_featureclass = workspace + r\"/LG_SD_LD_join\"\n",
    "# arcpy.SpatialJoin_analysis(SA_target_features, SA_join_features, LG_SD_LD_SA_out_featureclass, match_option=\"HAVE_THEIR_CENTER_IN\")\n",
    "# print(\"Secondary alteration domains joined.\\n\")\n",
    "\n",
    "# # Copy SD, LD, and SA indices to new feature class  \n",
    "# grid_LG_SD_LD_SA = workspace + \"/grid_LG_SD_LD_SA\"\n",
    "# arcpy.CopyFeatures_management(LG_SD_LD_SA_out_featureclass, grid_LG_SD_LD_SA)\n",
    "# print(\"Created new file:\", grid_LG_SD_LD_SA)\n",
    "\n",
    "print(\"\\nStep 1 complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
